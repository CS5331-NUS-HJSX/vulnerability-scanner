from crawlerhttp import CrawlerHttpSubmission, CrawlerHttpResponse

def readInput(path):
    inputs = []
    with open(path) as f:
        for line in f:
            inputs = inputs + [line.rstrip()]
    return inputs

redirectCodes = [301, 302, 303, 307, 308]

def attack(submissionList, inputsource, expectedsource, checkFailure = False, checkRedirect = False):
    dataForInput = readInput(inputsource)
    dataExpected = readInput(expectedsource)
    attackFormSubmission = []
    for submission in submissionList:
        print("Attacking " + submission.url)
        for i in dataForInput:
            duplicate = {}
            duplicate = submission.duplicate()
            duplicate.alterData(i)
            duplicateSubmission = duplicate.submit()
            if(duplicateSubmission is None):
                print("Attack failure")
                break
            else:
                appendToSubmissionResult = False

                if(checkFailure and int(duplicateSubmission.getCode()) == 500):
                    appendToSubmissionResult = True
                
                if(checkRedirect and int(duplicateSubmission.getCode()) in redirectCodes):
                    appendToSubmissionResult = True

                for e in dataExpected:
                    if duplicateSubmission.getPage().find(e) != -1:
                        appendToSubmissionResult = True
                        break
                
                if(appendToSubmissionResult):
                    print("Attack Successful")
                    attackFormSubmission = attackFormSubmission + [duplicate]   
                    break         
    return attackFormSubmission





