from crawlerhttp import CrawlerHttpSubmission, CrawlerHttpResponse

def readInput(path):
    inputs = []
    with open(path) as f:
        for line in f:
            inputs = inputs + [line.rstrip()]
    return inputs

def attack(submissionList, inputsource, expectedsource):
    dataForInput = readInput(inputsource)
    dataExpected = readInput(expectedsource)
    attackFormSubmission = []
    for submission in submissionList:
        print("Attacking " + submission.url)
        for i in dataForInput:
            duplicate = {}
            duplicate = submission.duplicate()
            duplicate.alterData(i)
            duplicateSubmission = duplicate.submit()
            if(duplicateSubmission is None):
                print(submission.pageUrl + " attack failure")
                break
            else:
                for e in dataExpected:
                    if duplicateSubmission.getPage().find(e) != -1:
                        attackFormSubmission = attackFormSubmission + [duplicate]            
                        break
    return attackFormSubmission





