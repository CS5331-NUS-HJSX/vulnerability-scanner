from crawlerhttp import CrawlerHttpSubmission, CrawlerHttpResponse

def readInput(path):
    inputs = []
    with open(path) as f:
        for line in f:
            inputs = inputs + [line.rstrip()]
    return inputs

def attack(submissionList, inputsource, expectedstring):
    dataForInput = readInput(inputsource)
    attackFormSubmission = []
    for submission in submissionList:
        print("Attacking " + submission.url)
        for i in dataForInput:
            duplicate = submission.duplicate()
            duplicate.alterData(i)
            duplicateSubmission = duplicate.submit()
            if(duplicateSubmission is None):
                print(submission.pageUrl + " attack failure")
                break
            else:
                if duplicateSubmission.getPage().find(expectedstring) != -1:
                    attackFormSubmission = attackFormSubmission + [duplicate]            
    return attackFormSubmission





